{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144fbbdf",
   "metadata": {},
   "source": [
    "Quora duplicate questions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3a7b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404351, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('quora_questions.csv')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82692ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120567</th>\n",
       "      <td>120567</td>\n",
       "      <td>238932</td>\n",
       "      <td>238933</td>\n",
       "      <td>How does the Boggart work?</td>\n",
       "      <td>What would the boggart of a boggart be?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324466</th>\n",
       "      <td>324466</td>\n",
       "      <td>636476</td>\n",
       "      <td>636477</td>\n",
       "      <td>What is difference between project manager and...</td>\n",
       "      <td>What are the differences between project manag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398558</th>\n",
       "      <td>398558</td>\n",
       "      <td>778728</td>\n",
       "      <td>778729</td>\n",
       "      <td>What hotel in Jabalpur would be safe for unmar...</td>\n",
       "      <td>What hotel in Allahabad would be safe for unma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339914</th>\n",
       "      <td>339914</td>\n",
       "      <td>666314</td>\n",
       "      <td>666315</td>\n",
       "      <td>What is stronger - Super Saiyan 4 or Super Sai...</td>\n",
       "      <td>How does Gohan turn into Super Saiyan 2?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185732</th>\n",
       "      <td>185732</td>\n",
       "      <td>366764</td>\n",
       "      <td>366765</td>\n",
       "      <td>How do I fill in Address Line 1 and Address Li...</td>\n",
       "      <td>How do I register desired web address?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "120567  120567  238932  238933   \n",
       "324466  324466  636476  636477   \n",
       "398558  398558  778728  778729   \n",
       "339914  339914  666314  666315   \n",
       "185732  185732  366764  366765   \n",
       "\n",
       "                                                question1  \\\n",
       "120567                         How does the Boggart work?   \n",
       "324466  What is difference between project manager and...   \n",
       "398558  What hotel in Jabalpur would be safe for unmar...   \n",
       "339914  What is stronger - Super Saiyan 4 or Super Sai...   \n",
       "185732  How do I fill in Address Line 1 and Address Li...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "120567            What would the boggart of a boggart be?             0  \n",
       "324466  What are the differences between project manag...             0  \n",
       "398558  What hotel in Allahabad would be safe for unma...             0  \n",
       "339914           How does Gohan turn into Super Saiyan 2?             0  \n",
       "185732             How do I register desired web address?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('quora_questions.csv')\n",
    "\n",
    "df = df.sample(n=40000,random_state=42)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd51041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df['question1'].values.tolist()\n",
    "q2 = df['question2'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5a897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       0\n",
      "is_duplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503480cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated and null rows\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46aefc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 0: 63.06%\n",
      "Percentage of 1: 36.94%\n"
     ]
    }
   ],
   "source": [
    "# see data distribution\n",
    "\n",
    "val = df['is_duplicate'].value_counts()\n",
    "zc=val[0]\n",
    "oc=val[1]\n",
    "print(f\"Percentage of 0: {zc*100/(zc+oc):.2f}%\")\n",
    "print(f\"Percentage of 1: {oc*100/(zc+oc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46fac4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['question1','question2']].values\n",
    "Y = df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22657850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3680f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags using BeautifulSoup\"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return text\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "exclude = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "def remove_punctuation(s:str)->str:\n",
    "    return s.translate(str.maketrans('','',exclude))\n",
    "\n",
    "def remove_url(s: str) -> str:\n",
    "    \"\"\"Remove URLs from string - simple and effective\"\"\"\n",
    "    if not isinstance(s, str) or not s:\n",
    "        return s\n",
    "    \n",
    "    # Pattern that catches most URLs\n",
    "    url_pattern = r'http[s]?://\\S+|www\\.\\S+|\\S+\\.(com|org|net|edu|gov|io|co)\\S*'\n",
    "    \n",
    "    # Remove URLs\n",
    "    clean_text = re.sub(url_pattern, '', s, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up spaces\n",
    "    return ' '.join(clean_text.split()) \n",
    "\n",
    "def pre_process_paragraph(s:str)->list[str]:\n",
    "    # lowercase and stripping\n",
    "    s = s.strip().lower()\n",
    "\n",
    "    # removing urls, punctuations and html tags + [math] substrings\n",
    "    s = re.sub(r'\\[math\\].*?\\[/math\\]', '', s)\n",
    "    s = remove_url(remove_punctuation(remove_html_tags(s)))\n",
    "\n",
    "    # Clean up extra whitespace\n",
    "    s = ' '.join(s.split())\n",
    "\n",
    "    # word level tokenize\n",
    "    tokenized_para = word_tokenize(s)\n",
    "\n",
    "    # removing stopwords\n",
    "    tokenized_para = [ele for ele in tokenized_para if ele not in stop_words]\n",
    "\n",
    "    # spell checker (skip for performance)\n",
    "\n",
    "    # stemming (skip for performance)\n",
    "\n",
    "    return tokenized_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0535c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [pre_process_paragraph(q1) for q1,_ in x_train]\n",
    "corpus.extend([pre_process_paragraph(q2) for _,q2 in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dece48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14c52211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(workers=6,window=3,vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb031e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aac15675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1528852, 1774560)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(corpus,epochs=model.epochs,total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17280637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\w2v_duplicate_.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save word2vec model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model,'models\\\\w2v_duplicate_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74892a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzywuzzy.fuzz as fuzz\n",
    "import joblib\n",
    "\n",
    "model = joblib.load('models\\\\w2v_duplicate_.pkl')\n",
    "\n",
    "def word_level_w2v(s):\n",
    "    \"\"\"Get word vector with error handling\"\"\"\n",
    "    try:\n",
    "        return model.wv[s]\n",
    "    except KeyError:\n",
    "        # Return zero vector if word not in vocabulary\n",
    "        return np.zeros(model.wv.vector_size)\n",
    "\n",
    "def getCommonWords(s1:str,s2:str):\n",
    "    st1 = set(s1.split())\n",
    "    st2 = set(s2.split())\n",
    "    \n",
    "    return len(st1 & st2)\n",
    "\n",
    "def getCommonStopwords(s1:str,s2:str):\n",
    "    words1 = set(s1.split())\n",
    "    words2 = set(s2.split())\n",
    "\n",
    "    return len(words1 & stop_words & words2)\n",
    "\n",
    "def getTotalUniqueWords(s1:str,s2:str):\n",
    "    st1 = set(s1.split())\n",
    "    st2 = set(s2.split())\n",
    "    \n",
    "    return len(st1) + len(st2)\n",
    "\n",
    "def getStopwordsCount(s1:str):\n",
    "    return len(stop_words & set(s1.split()))\n",
    "\n",
    "def getLongestSubstringRatio(s1: str, s2: str) -> float:\n",
    "    \"\"\"Optimized longest common substring ratio calculation\"\"\"\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "    \n",
    "    s1, s2 = s1.lower(), s2.lower()\n",
    "    m, n = len(s1), len(s2)\n",
    "    \n",
    "    # Use rolling arrays to save memory\n",
    "    prev = [0] * (n + 1)\n",
    "    curr = [0] * (n + 1)\n",
    "    \n",
    "    max_length = 0\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                curr[j] = prev[j-1] + 1\n",
    "                max_length = max(max_length, curr[j])\n",
    "            else:\n",
    "                curr[j] = 0\n",
    "        \n",
    "        # Swap arrays\n",
    "        prev, curr = curr, prev\n",
    "    \n",
    "    min_length = min(m, n)\n",
    "    return max_length / min_length if min_length > 0 else 0.0\n",
    "\n",
    "def getFuzzyMetrics(s1,s2):\n",
    "    # fuzz ratio\n",
    "    fuzz_ratio = fuzz.ratio(s1,s2)\n",
    "\n",
    "    # fuzz_partial_ratio\n",
    "    fuzz_partial_ratio = fuzz.partial_ratio(s1,s2)\n",
    "\n",
    "    # fuzz_sort_ratio\n",
    "    fuzz_set_ratio = fuzz.token_sort_ratio(s1,s2)\n",
    "\n",
    "    # fuzz set ratio\n",
    "    fuzz_token_ratio = fuzz.token_set_ratio(s1,s2)\n",
    "\n",
    "    return fuzz_ratio,fuzz_partial_ratio,fuzz_set_ratio,fuzz_token_ratio\n",
    "\n",
    "def w2v_sentence(s1:str,s2:str):\n",
    "    tokens_s1 = pre_process_paragraph(s1)\n",
    "    tokens_s2 = pre_process_paragraph(s2)\n",
    "\n",
    "    # 1. self engineered features\n",
    "\n",
    "    n_chars1 = len(s1)\n",
    "    n_chars2 = len(s2)\n",
    "    n_words1 = len(s1.split())\n",
    "    n_words2 = len(s2.split())\n",
    "    common_words = getCommonWords(s1,s2)\n",
    "    total_unique_words = getTotalUniqueWords(s1,s2)\n",
    "    common_ratio = common_words / total_unique_words\n",
    "    common_stopwords = getCommonStopwords(s1,s2)\n",
    "    stopwords1 = getStopwordsCount(s1)\n",
    "    stopwords2 = getStopwordsCount(s2)\n",
    "    common_tokens = len(set(tokens_s1) & set(tokens_s2))\n",
    "    tokens1 = len(set(tokens_s1))\n",
    "    tokens2 = len(set(tokens_s2))\n",
    "\n",
    "    # 1.1 token level features\n",
    "    cwc_min = common_words/min(n_words1,n_words2)\n",
    "    cwc_max = common_words/max(n_words1,n_words2)\n",
    "    csc_min = common_stopwords/min(stopwords1,stopwords2) if min(stopwords1,stopwords2) else 0.0\n",
    "    csc_max = common_stopwords/max(stopwords1,stopwords2) if max(stopwords1,stopwords2) else 0.0\n",
    "    ctc_min = common_tokens/min(tokens1,tokens2) if min(tokens1,tokens2) else 0.0\n",
    "    ctc_max = common_tokens/max(tokens1,tokens2) if max(tokens1,tokens2) else 0.0\n",
    "    last_word_eq = bool(s1.split()[-1]==s2.split()[-1])\n",
    "    first_word_eq = bool(s1.split()[0]==s2.split()[0])\n",
    "\n",
    "    mean_length = (n_words1 + n_words2) / 2\n",
    "    abs_len_diff = abs(n_words2 - n_words1)\n",
    "    longest_substring_ratio = getLongestSubstringRatio(s1,s2)\n",
    "\n",
    "    fuzz_ratio,fuzz_partial_ratio,fuzz_set_ratio,fuzz_token_ratio = getFuzzyMetrics(s1,s2)\n",
    "\n",
    "    v1 = [word_level_w2v(ele) for ele in tokens_s1] or [np.zeros(model.wv.vector_size)]\n",
    "    v2 = [word_level_w2v(ele) for ele in tokens_s2] or [np.zeros(model.wv.vector_size)]\n",
    "\n",
    "    # additional features vector\n",
    "    additional_vec = [n_chars1,n_chars2,n_words1,n_words2,common_words,total_unique_words,common_ratio]\n",
    "    additional_vec.extend([cwc_min,cwc_max,csc_min,csc_max,ctc_min,ctc_max,last_word_eq,first_word_eq])\n",
    "    additional_vec.extend([mean_length,abs_len_diff,longest_substring_ratio])\n",
    "    additional_vec.extend([fuzz_ratio,fuzz_partial_ratio,fuzz_set_ratio,fuzz_token_ratio])\n",
    "\n",
    "    final_feature_vector = np.mean(np.concatenate([v1,v2]),axis=0)\n",
    "    final_feature_vector = np.concatenate([final_feature_vector,additional_vec])\n",
    "\n",
    "    return final_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1014e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCommonStopwords('this is akash','this here is akash and papa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "869cfc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66666667,  1.        ,  0.        ,  5.5       ,  1.        ,\n",
       "        0.4       , 67.        , 70.        , 57.        , 76.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_sentence('i want to become ias','how do i become an ias')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c3cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_real = [w2v_sentence(s1,s2) for s1,s2 in x_train]\n",
    "x_test_real = [w2v_sentence(s1,s2) for s1,s2 in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ca15f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              class_weight=&#x27;balanced&#x27;, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "              min_child_weight=None, min_samples_leaf=5, min_samples_split=10,\n",
       "              missing=nan, monotone_constraints=None, multi_strategy=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              class_weight='balanced', colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "              min_child_weight=None, min_samples_leaf=5, min_samples_split=10,\n",
       "              missing=nan, monotone_constraints=None, multi_strategy=None, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,              \n",
    "    min_samples_split=10,       \n",
    "    min_samples_leaf=5,           \n",
    "    random_state=42,                 \n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "xgb.fit(x_train_real,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afe016a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models//xgb_model.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(xgb,'models//xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "169bffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7957\n",
      "Precision: 0.7217\n",
      "Recall: 0.7300\n",
      "F1 score: 0.7258\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "xgb_model = joblib.load('models\\\\xgb_model.pkl')\n",
    "\n",
    "y_pred = xgb_model.predict(x_test_real)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_pred=y_pred,y_true=y_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred=y_pred,y_true=y_test):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred=y_pred,y_true=y_test):.4f}\")\n",
    "print(f\"F1 score: {f1_score(y_pred=y_pred,y_true=y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9417bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Duplicate\n",
      "Prediction took 0.0521 seconds\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "xgb_model = joblib.load('models\\\\xgb_model.pkl')\n",
    "\n",
    "s1 = 'where do i learn data science'\n",
    "s2 = 'resources to get started with data science'\n",
    "\n",
    "sample1 = w2v_sentence(s1,s2)\n",
    "\n",
    "y_pred = xgb_model.predict([sample1])\n",
    "print(\"Duplicate\" if y_pred==1 else 'Non Duplicate')\n",
    "print(f\"Prediction took {time()-start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d889e",
   "metadata": {},
   "source": [
    "# Model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46671b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"quora_questions.csv\").sample(n=100000,random_state=42)\n",
    "df = pd.read_csv(\"quora_questions.csv\")\n",
    "\n",
    "# Drop rows with missing values BEFORE splitting\n",
    "df = df.dropna(subset=['question1', 'question2'])\n",
    "\n",
    "X = df[['question1','question2']].values\n",
    "Y = df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7fcd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test_val,y_train,y_test_val = train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "x_val,x_test,y_val,y_test = train_test_split(x_test_val,y_test_val,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45870e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements in corpus: 56841\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique elements in corpus: {len(set(tuple(x) for x in corpus))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7724c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<UNK>':0}\n",
    "for tokenized_sentence in corpus:\n",
    "    for word in tokenized_sentence:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9755100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_to_indices(s:str):\n",
    "    arr = []\n",
    "    for word in pre_process_paragraph(s):\n",
    "        arr.append(0 if word not in vocab else vocab[word])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98329147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = [np.concatenate([para_to_indices(sen1),para_to_indices(sen2)]) for sen1,sen2 in x_train]\n",
    "x_val = [np.concatenate([para_to_indices(sen1),para_to_indices(sen2)]) for sen1,sen2 in x_val]\n",
    "x_test = [np.concatenate([para_to_indices(sen1),para_to_indices(sen2)]) for sen1,sen2 in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2d870f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # self.x[index] is already a concatenated numpy array of indices\n",
    "        return torch.tensor(self.x[index], dtype=torch.long), torch.tensor(self.y[index], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58908beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train,y_train)\n",
    "val_dataset = CustomDataset(x_val,y_val)\n",
    "test_dataset = CustomDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "faa9657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def collate_pad(batch):\n",
    "    \"\"\"\n",
    "    Collate function to pad sequences in a batch to the same length.\n",
    "    Args:\n",
    "        batch: list of (tensor, label) tuples\n",
    "    Returns:\n",
    "        padded_tensors: tensor of shape (batch_size, max_seq_len)\n",
    "        labels: tensor of shape (batch_size,)\n",
    "    \"\"\"\n",
    "    sequences, labels = zip(*batch)\n",
    "    # Pad sequences to the length of the longest sequence in the batch\n",
    "    padded_tensors = pad_sequence(sequences, batch_first=True, padding_value=0) # type:ignore\n",
    "    labels = torch.stack(labels)\n",
    "    return padded_tensors, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=8,collate_fn=collate_pad)\n",
    "val_loader = DataLoader(val_dataset,batch_size=16,shuffle=True,collate_fn=collate_pad)\n",
    "test_loader = DataLoader(test_dataset,batch_size=16,shuffle=True,collate_fn=collate_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2b62e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=150, dropout=0.3, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            num_layers=4,\n",
    "            dropout=dropout,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear = nn.Linear(hidden_size * 2, 1)  # hidden_size * 2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.embedding(x)\n",
    "        _, (hd, _) = self.lstm(embedding)\n",
    "        # hd shape: (num_layers * num_directions, batch, hidden_size)\n",
    "        # For bidirectional, concatenate last layer's forward and backward hidden states\n",
    "        out = torch.cat((hd[-2], hd[-1]), dim=1)  # shape: (batch, hidden_size*2)\n",
    "        out = self.dropout(out)\n",
    "        return self.linear(out).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c41a38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "\n",
    "# class MyNN(nn.Module):\n",
    "#     def __init__(self, embedding_dim=256, num_heads=4, num_layers=4, dropout=0.3):\n",
    "#         super().__init__()\n",
    "#         self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
    "#         encoder_layer = nn.TransformerEncoderLayer(\n",
    "#             d_model=embedding_dim,\n",
    "#             nhead=num_heads,\n",
    "#             dropout=dropout,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "#         self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "#         self.linear = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         emb = self.embedding(x)\n",
    "#         out = self.transformer(emb)\n",
    "#         out = out.mean(dim=1)  # Pooling\n",
    "#         return self.linear(out).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ffa1835",
   "metadata": {},
   "outputs": [],
   "source": [
    "neta = 2e-4\n",
    "lambda_ = 3e-4\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b92562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and device\n",
    "model = MyNN()\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=neta,weight_decay=lambda_)\n",
    "\n",
    "# loss fn\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "75fb3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ====> Train Loss: 0.5478 | Val Loss: 0.5239\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 ====> Train Loss: 0.5264 | Val Loss: 0.5175\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 ====> Train Loss: 0.5212 | Val Loss: 0.5129\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 ====> Train Loss: 0.5171 | Val Loss: 0.5098\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 ====> Train Loss: 0.5129 | Val Loss: 0.5074\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 ====> Train Loss: 0.5094 | Val Loss: 0.5047\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 ====> Train Loss: 0.5055 | Val Loss: 0.5037\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 ====> Train Loss: 0.5024 | Val Loss: 0.5019\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 ====> Train Loss: 0.5005 | Val Loss: 0.5014\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 ====> Train Loss: 0.4994 | Val Loss: 0.5007\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 ====> Train Loss: 0.4980 | Val Loss: 0.5004\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 ====> Train Loss: 0.4972 | Val Loss: 0.5000\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 ====> Train Loss: 0.4963 | Val Loss: 0.4988\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 ====> Train Loss: 0.4947 | Val Loss: 0.4984\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 ====> Train Loss: 0.4932 | Val Loss: 0.4985\n",
      "⚠️  No improvement. Patience: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 ====> Train Loss: 0.4923 | Val Loss: 0.4985\n",
      "⚠️  No improvement. Patience: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 ====> Train Loss: 0.4916 | Val Loss: 0.4982\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 ====> Train Loss: 0.4910 | Val Loss: 0.4978\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 ====> Train Loss: 0.4900 | Val Loss: 0.4978\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 ====> Train Loss: 0.4894 | Val Loss: 0.4978\n",
      "⚠️  No improvement. Patience: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 ====> Train Loss: 0.4886 | Val Loss: 0.4968\n",
      "✅ Validation loss improved! Saving best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 ====> Train Loss: 0.4878 | Val Loss: 0.4977\n",
      "⚠️  No improvement. Patience: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 ====> Train Loss: 0.4870 | Val Loss: 0.4984\n",
      "⚠️  No improvement. Patience: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 ====> Train Loss: 0.4861 | Val Loss: 0.4985\n",
      "⚠️  No improvement. Patience: 3/3\n",
      "🛑 Early stopping triggered after 24 epochs!\n",
      "\n",
      "✅ Training completed! Best validation loss: 0.4968\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop with early stopping\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Add progress bar for training\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]', leave=False)\n",
    "    for train_data, train_label in train_pbar:\n",
    "        # Move to device\n",
    "        train_data, train_label = train_data.to(device), train_label.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(train_data)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = loss_fn(out, train_label)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    # Add progress bar for validation\n",
    "    val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]', leave=False)\n",
    "    with torch.no_grad():\n",
    "        for val_data, val_label in val_pbar:\n",
    "            val_data, val_label = val_data.to(device), val_label.to(device)\n",
    "            val_out = model(val_data)\n",
    "            batch_loss = loss_fn(val_out, val_label).item()\n",
    "            val_loss += batch_loss\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            val_pbar.set_postfix({'loss': f'{batch_loss:.4f}'})\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1} ====> Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model state\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"✅ Validation loss improved! Saving best model...\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"⚠️  No improvement. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"🛑 Early stopping triggered after {epoch+1} epochs!\")\n",
    "            # Load best model state\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "print(f\"\\n✅ Training completed! Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b151485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluating model on testing data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7578025819003182,\n",
       " 'precision': 0.7339561580265006,\n",
       " 'recall': 0.5377354270120341,\n",
       " 'f1_score': 0.6207074619158275}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Fixed evaluation function\n",
    "def evaluate_rnn_model():\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch, test_labels in test_loader:\n",
    "            test_batch, test_labels = test_batch.to(device), test_labels.to(device)\n",
    "\n",
    "            y_pred = model(test_batch)\n",
    "            \n",
    "            # Fixed prediction calculation for sigmoid output\n",
    "            predictions = (torch.sigmoid(y_pred) > 0.5).float()\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "# Run evaluation\n",
    "print(\"📊 Evaluating model on testing data...\")\n",
    "evaluate_rnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f962d",
   "metadata": {},
   "source": [
    "# Using pre-trained bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8ddec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NROWS = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c51c789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91748\\OneDrive\\Desktop\\duplicate question classifier\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 139999\n",
      "Validation size: 30000\n",
      "Test size: 30000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Reload original data for BERT\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('quora_questions.csv', nrows=NROWS)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(subset=['question1', 'question2', 'is_duplicate'], inplace=True)\n",
    "\n",
    "X = df[['question1','question2']].values\n",
    "Y = df['is_duplicate'].values\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "x_train_bert, x_temp, y_train_bert, y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "x_val_bert, x_test_bert, y_val_bert, y_test_bert = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Extract questions and convert to strings\n",
    "train_q1 = [str(pair[0]) for pair in x_train_bert]\n",
    "train_q2 = [str(pair[1]) for pair in x_train_bert] \n",
    "val_q1 = [str(pair[0]) for pair in x_val_bert]\n",
    "val_q2 = [str(pair[1]) for pair in x_val_bert]\n",
    "test_q1 = [str(pair[0]) for pair in x_test_bert]\n",
    "test_q2 = [str(pair[1]) for pair in x_test_bert]\n",
    "\n",
    "# Create encodings and datasets\n",
    "train_encodings = tokenizer(train_q1, train_q2, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "train_dataset = CustomDataset(train_encodings, y_train_bert)\n",
    "\n",
    "val_encodings = tokenizer(val_q1, val_q2, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "val_dataset = CustomDataset(val_encodings, y_val_bert)\n",
    "\n",
    "test_encodings = tokenizer(test_q1, test_q2, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "test_dataset = CustomDataset(test_encodings, y_test_bert)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6445514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865119f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers.trainer import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model = model.to(device)  # 🎯 Move model to GPU\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    # For binary classification with 2 labels\n",
    "    preds = logits.argmax(-1)  # Get predicted class (0 or 1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels,preds)\n",
    "    return {\"accuracy\": acc, 'f1_score':f1, \"precision\":precision,\"recall\":recall}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,          # 2-4 is guud\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=1e-5,          # Lower LR\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  # Your processed train CustomDataset\n",
    "    eval_dataset=val_dataset,    # Your processed test CustomDataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d7a079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52500' max='52500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52500/52500 7:26:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.344500</td>\n",
       "      <td>0.330446</td>\n",
       "      <td>0.869433</td>\n",
       "      <td>0.834131</td>\n",
       "      <td>0.787227</td>\n",
       "      <td>0.886978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.392492</td>\n",
       "      <td>0.878833</td>\n",
       "      <td>0.841564</td>\n",
       "      <td>0.815440</td>\n",
       "      <td>0.869416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.235900</td>\n",
       "      <td>0.475074</td>\n",
       "      <td>0.883767</td>\n",
       "      <td>0.847269</td>\n",
       "      <td>0.824763</td>\n",
       "      <td>0.871037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=52500, training_loss=0.308428998819987, metrics={'train_runtime': 26783.1862, 'train_samples_per_second': 15.681, 'train_steps_per_second': 1.96, 'total_flos': 2.762646347950848e+16, 'train_loss': 0.308428998819987, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdab3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint='results/checkpoint-10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd25406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest checkpoint: ./results/checkpoint-52500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 04:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4768\n",
      "Test Accuracy: 88.21%\n",
      "Precision: 81.84%\n",
      "Recall: 87.28%\n",
      "F1 Score: 84.47%\n"
     ]
    }
   ],
   "source": [
    "# Final testing on pristine testing dataset\n",
    "\n",
    "import os,re\n",
    "\n",
    "# Find the latest checkpoint automatically\n",
    "results_dir = './results'\n",
    "checkpoints = [d for d in os.listdir(results_dir) if d.startswith('checkpoint-')]\n",
    "\n",
    "if checkpoints:\n",
    "    # Extract checkpoint numbers and find the maximum\n",
    "    checkpoint_numbers = [int(re.search(r'checkpoint-(\\d+)', cp).group(1)) for cp in checkpoints] # type:ignore\n",
    "    latest_checkpoint_num = max(checkpoint_numbers)\n",
    "    model_path = f'{results_dir}/checkpoint-{latest_checkpoint_num}'\n",
    "    print(f\"Loading latest checkpoint: {model_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No checkpoints found in ./results directory\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  # Your processed train CustomDataset\n",
    "    eval_dataset=test_dataset,    # Your processed test CustomDataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "def evaluate_bert_model(trainer):\n",
    "    results = trainer.evaluate()\n",
    "    print(f\"Test Loss: {results['eval_loss']:.4f}\")\n",
    "    print(f\"Test Accuracy: {results['eval_accuracy']*100:.2f}%\" if 'eval_accuracy' in results else \"Accuracy: NA\")\n",
    "    print(f\"Precision: {results['eval_precision']*100:.2f}%\" if 'eval_precision' in results else \"Precision: NA\")\n",
    "    print(f\"Recall: {results['eval_recall']*100:.2f}%\" if 'eval_recall' in results else \"Recall: NA\")\n",
    "    print(f\"F1 Score: {results['eval_f1_score']*100:.2f}%\" if 'eval_f1_score' in results else \"F1 Score: NA\")\n",
    "\n",
    "evaluate_bert_model(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c5f1bf",
   "metadata": {},
   "source": [
    "# Real-world usage of BERT fine-tuned solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74dabe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest checkpoint: ./results/checkpoint-10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Find the latest checkpoint automatically\n",
    "results_dir = './results'\n",
    "checkpoints = [d for d in os.listdir(results_dir) if d.startswith('checkpoint-')]\n",
    "\n",
    "if checkpoints:\n",
    "    # Extract checkpoint numbers and find the maximum\n",
    "    checkpoint_numbers = [int(re.search(r'checkpoint-(\\d+)', cp).group(1)) for cp in checkpoints] # type:ignore\n",
    "    latest_checkpoint_num = max(checkpoint_numbers)\n",
    "    model_path = f'{results_dir}/checkpoint-{latest_checkpoint_num}'\n",
    "    print(f\"Loading latest checkpoint: {model_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No checkpoints found in ./results directory\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4624e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_duplicate(question1, question2):\n",
    "    \"\"\"\n",
    "    Predict if two questions are duplicates using the trained BERT model\n",
    "    \n",
    "    Args:\n",
    "        question1 (str): First question\n",
    "        question2 (str): Second question  \n",
    "        model_path (str): Path to saved model checkpoint\n",
    "        \n",
    "    Returns:\n",
    "        dict: Prediction results with probability and classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\n",
    "        question1, \n",
    "        question2,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get probabilities\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Probability of being duplicate (class 1)\n",
    "        duplicate_prob = probabilities[0][1].item()\n",
    "    \n",
    "    return {\n",
    "        'duplicate_probability': duplicate_prob\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59dd97ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Probability: 0.2776\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "result = predict_duplicate(\n",
    "    \"what is the process of coming late?\",\n",
    "    \"what is the process of coming on time?\"\n",
    ")\n",
    "\n",
    "print(f\"Duplicate Probability: {result['duplicate_probability']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740aa9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
