{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144fbbdf",
   "metadata": {},
   "source": [
    "Quora duplicate questions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c3a7b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404351, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('..\\\\csvs\\\\quora_questions.csv')\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82692ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120567</th>\n",
       "      <td>120567</td>\n",
       "      <td>238932</td>\n",
       "      <td>238933</td>\n",
       "      <td>How does the Boggart work?</td>\n",
       "      <td>What would the boggart of a boggart be?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324466</th>\n",
       "      <td>324466</td>\n",
       "      <td>636476</td>\n",
       "      <td>636477</td>\n",
       "      <td>What is difference between project manager and...</td>\n",
       "      <td>What are the differences between project manag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398558</th>\n",
       "      <td>398558</td>\n",
       "      <td>778728</td>\n",
       "      <td>778729</td>\n",
       "      <td>What hotel in Jabalpur would be safe for unmar...</td>\n",
       "      <td>What hotel in Allahabad would be safe for unma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339914</th>\n",
       "      <td>339914</td>\n",
       "      <td>666314</td>\n",
       "      <td>666315</td>\n",
       "      <td>What is stronger - Super Saiyan 4 or Super Sai...</td>\n",
       "      <td>How does Gohan turn into Super Saiyan 2?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185732</th>\n",
       "      <td>185732</td>\n",
       "      <td>366764</td>\n",
       "      <td>366765</td>\n",
       "      <td>How do I fill in Address Line 1 and Address Li...</td>\n",
       "      <td>How do I register desired web address?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "120567  120567  238932  238933   \n",
       "324466  324466  636476  636477   \n",
       "398558  398558  778728  778729   \n",
       "339914  339914  666314  666315   \n",
       "185732  185732  366764  366765   \n",
       "\n",
       "                                                question1  \\\n",
       "120567                         How does the Boggart work?   \n",
       "324466  What is difference between project manager and...   \n",
       "398558  What hotel in Jabalpur would be safe for unmar...   \n",
       "339914  What is stronger - Super Saiyan 4 or Super Sai...   \n",
       "185732  How do I fill in Address Line 1 and Address Li...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "120567            What would the boggart of a boggart be?             0  \n",
       "324466  What are the differences between project manag...             0  \n",
       "398558  What hotel in Allahabad would be safe for unma...             0  \n",
       "339914           How does Gohan turn into Super Saiyan 2?             0  \n",
       "185732             How do I register desired web address?             0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('..\\\\csvs\\\\quora_questions.csv')\n",
    "\n",
    "df = df.sample(n=40000,random_state=42)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd51041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df['question1'].values.tolist()\n",
    "q2 = df['question2'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c5a897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       0\n",
      "is_duplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503480cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# remove duplicated and null rows\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf\u001b[49m.drop_duplicates(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m df.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# remove duplicated and null rows\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46aefc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 0: 63.06%\n",
      "Percentage of 1: 36.94%\n"
     ]
    }
   ],
   "source": [
    "# see data distribution\n",
    "\n",
    "val = df['is_duplicate'].value_counts()\n",
    "zc=val[0]\n",
    "oc=val[1]\n",
    "print(f\"Percentage of 0: {zc*100/(zc+oc):.2f}%\")\n",
    "print(f\"Percentage of 1: {oc*100/(zc+oc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46fac4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['question1','question2']].values\n",
    "Y = df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22657850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3680f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags using BeautifulSoup\"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return text\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "exclude = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "def remove_punctuation(s:str)->str:\n",
    "    return s.translate(str.maketrans('','',exclude))\n",
    "\n",
    "def remove_url(s: str) -> str:\n",
    "    \"\"\"Remove URLs from string - simple and effective\"\"\"\n",
    "    if not isinstance(s, str) or not s:\n",
    "        return s\n",
    "    \n",
    "    # Pattern that catches most URLs\n",
    "    url_pattern = r'http[s]?://\\S+|www\\.\\S+|\\S+\\.(com|org|net|edu|gov|io|co)\\S*'\n",
    "    \n",
    "    # Remove URLs\n",
    "    clean_text = re.sub(url_pattern, '', s, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up spaces\n",
    "    return ' '.join(clean_text.split()) \n",
    "\n",
    "def pre_process_paragraph(s:str)->list[str]:\n",
    "    # lowercase and stripping\n",
    "    s = s.strip().lower()\n",
    "\n",
    "    # removing urls, punctuations and html tags + [math] substrings\n",
    "    s = re.sub(r'\\[math\\].*?\\[/math\\]', '', s)\n",
    "    s = remove_url(remove_punctuation(remove_html_tags(s)))\n",
    "\n",
    "    # Clean up extra whitespace\n",
    "    s = ' '.join(s.split())\n",
    "\n",
    "    # word level tokenize\n",
    "    tokenized_para = word_tokenize(s)\n",
    "\n",
    "    # removing stopwords\n",
    "    tokenized_para = [ele for ele in tokenized_para if ele not in stop_words]\n",
    "\n",
    "    # spell checker (skip for performance)\n",
    "\n",
    "    # stemming (skip for performance)\n",
    "\n",
    "    return tokenized_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d0535c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [pre_process_paragraph(q1) for q1,_ in x_train]\n",
    "corpus.extend([pre_process_paragraph(q2) for _,q2 in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dece48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14c52211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(workers=6,window=3,vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb031e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac15675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16784397, 17956735)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(corpus,epochs=model.epochs,total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17280637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\models\\\\w2v_duplicate_.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save word2vec model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model,'..\\\\models\\\\w2v_duplicate_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74892a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzywuzzy.fuzz as fuzz\n",
    "import joblib\n",
    "\n",
    "model = joblib.load('..\\\\models\\\\w2v_duplicate_.pkl')\n",
    "\n",
    "def word_level_w2v(s):\n",
    "    \"\"\"Get word vector with error handling\"\"\"\n",
    "    try:\n",
    "        return model.wv[s]\n",
    "    except KeyError:\n",
    "        # Return zero vector if word not in vocabulary\n",
    "        return np.zeros(model.wv.vector_size)\n",
    "\n",
    "def getCommonWords(s1:str,s2:str):\n",
    "    st1 = set(s1.split())\n",
    "    st2 = set(s2.split())\n",
    "    \n",
    "    return len(st1 & st2)\n",
    "\n",
    "def getCommonStopwords(s1:str,s2:str):\n",
    "    words1 = set(s1.split())\n",
    "    words2 = set(s2.split())\n",
    "\n",
    "    return len(words1 & stop_words & words2)\n",
    "\n",
    "def getTotalUniqueWords(s1:str,s2:str):\n",
    "    st1 = set(s1.split())\n",
    "    st2 = set(s2.split())\n",
    "    \n",
    "    return len(st1) + len(st2)\n",
    "\n",
    "def getStopwordsCount(s1:str):\n",
    "    return len(stop_words & set(s1.split()))\n",
    "\n",
    "def getLongestSubstringRatio(s1: str, s2: str) -> float:\n",
    "    \"\"\"Optimized longest common substring ratio calculation\"\"\"\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "    \n",
    "    s1, s2 = s1.lower(), s2.lower()\n",
    "    m, n = len(s1), len(s2)\n",
    "    \n",
    "    # Use rolling arrays to save memory\n",
    "    prev = [0] * (n + 1)\n",
    "    curr = [0] * (n + 1)\n",
    "    \n",
    "    max_length = 0\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                curr[j] = prev[j-1] + 1\n",
    "                max_length = max(max_length, curr[j])\n",
    "            else:\n",
    "                curr[j] = 0\n",
    "        \n",
    "        # Swap arrays\n",
    "        prev, curr = curr, prev\n",
    "    \n",
    "    min_length = min(m, n)\n",
    "    return max_length / min_length if min_length > 0 else 0.0\n",
    "\n",
    "def getFuzzyMetrics(s1,s2):\n",
    "    # fuzz ratio\n",
    "    fuzz_ratio = fuzz.ratio(s1,s2)\n",
    "\n",
    "    # fuzz_partial_ratio\n",
    "    fuzz_partial_ratio = fuzz.partial_ratio(s1,s2)\n",
    "\n",
    "    # fuzz_sort_ratio\n",
    "    fuzz_set_ratio = fuzz.token_sort_ratio(s1,s2)\n",
    "\n",
    "    # fuzz set ratio\n",
    "    fuzz_token_ratio = fuzz.token_set_ratio(s1,s2)\n",
    "\n",
    "    return fuzz_ratio,fuzz_partial_ratio,fuzz_set_ratio,fuzz_token_ratio\n",
    "\n",
    "def w2v_sentence(s1:str,s2:str):\n",
    "    tokens_s1 = pre_process_paragraph(s1)\n",
    "    tokens_s2 = pre_process_paragraph(s2)\n",
    "\n",
    "    # 1. self engineered features\n",
    "\n",
    "    n_chars1 = len(s1)\n",
    "    n_chars2 = len(s2)\n",
    "    n_words1 = len(s1.split())\n",
    "    n_words2 = len(s2.split())\n",
    "    common_words = getCommonWords(s1,s2)\n",
    "    total_unique_words = getTotalUniqueWords(s1,s2)\n",
    "    common_ratio = common_words / total_unique_words\n",
    "    common_stopwords = getCommonStopwords(s1,s2)\n",
    "    stopwords1 = getStopwordsCount(s1)\n",
    "    stopwords2 = getStopwordsCount(s2)\n",
    "    common_tokens = len(set(tokens_s1) & set(tokens_s2))\n",
    "    tokens1 = len(set(tokens_s1))\n",
    "    tokens2 = len(set(tokens_s2))\n",
    "\n",
    "    # 1.1 token level features\n",
    "    cwc_min = common_words/min(n_words1,n_words2)\n",
    "    cwc_max = common_words/max(n_words1,n_words2)\n",
    "    csc_min = common_stopwords/min(stopwords1,stopwords2) if min(stopwords1,stopwords2) else 0.0\n",
    "    csc_max = common_stopwords/max(stopwords1,stopwords2) if max(stopwords1,stopwords2) else 0.0\n",
    "    ctc_min = common_tokens/min(tokens1,tokens2) if min(tokens1,tokens2) else 0.0\n",
    "    ctc_max = common_tokens/max(tokens1,tokens2) if max(tokens1,tokens2) else 0.0\n",
    "    last_word_eq = bool(s1.split()[-1]==s2.split()[-1])\n",
    "    first_word_eq = bool(s1.split()[0]==s2.split()[0])\n",
    "\n",
    "    mean_length = (n_words1 + n_words2) / 2\n",
    "    abs_len_diff = abs(n_words2 - n_words1)\n",
    "    longest_substring_ratio = getLongestSubstringRatio(s1,s2)\n",
    "\n",
    "    fuzz_ratio,fuzz_partial_ratio,fuzz_set_ratio,fuzz_token_ratio = getFuzzyMetrics(s1,s2)\n",
    "\n",
    "    v1 = [word_level_w2v(ele) for ele in tokens_s1] or [np.zeros(model.wv.vector_size)]\n",
    "    v2 = [word_level_w2v(ele) for ele in tokens_s2] or [np.zeros(model.wv.vector_size)]\n",
    "\n",
    "    # additional features vector\n",
    "    additional_vec = [n_chars1,n_chars2,n_words1,n_words2,common_words,total_unique_words,common_ratio]\n",
    "    additional_vec.extend([cwc_min,cwc_max,csc_min,csc_max,ctc_min,ctc_max,last_word_eq,first_word_eq])\n",
    "    additional_vec.extend([mean_length,abs_len_diff,longest_substring_ratio])\n",
    "    additional_vec.extend([fuzz_ratio,fuzz_partial_ratio,fuzz_set_ratio,fuzz_token_ratio])\n",
    "\n",
    "    final_feature_vector = np.mean(np.concatenate([v1,v2]),axis=0)\n",
    "    final_feature_vector = np.concatenate([final_feature_vector,additional_vec])\n",
    "\n",
    "    return final_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1014e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCommonStopwords('this is akash','this here is akash and papa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "869cfc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66666667,  1.        ,  0.        ,  5.5       ,  1.        ,\n",
       "        0.4       , 57.        , 69.        , 57.        , 76.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_sentence('i want to become ias','how do i become an ias')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8c3cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_real = [w2v_sentence(s1,s2) for s1,s2 in x_train]\n",
    "x_test_real = [w2v_sentence(s1,s2) for s1,s2 in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ca15f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=5, min_samples_split=10,\n",
       "                       n_estimators=300, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                       min_samples_leaf=5, min_samples_split=10,\n",
       "                       n_estimators=300, random_state=42)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,              \n",
    "    min_samples_split=10,       \n",
    "    min_samples_leaf=5,           \n",
    "    random_state=42,                 \n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf.fit(x_train_real,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "169bffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8089\n",
      "Precision: 0.6868\n",
      "Recall: 0.8793\n",
      "F1 score: 0.7713\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "rf_model = joblib.load('..\\\\models\\\\duplicate_.pkl')\n",
    "\n",
    "y_pred = rf_model.predict(x_test_real)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_pred=y_pred,y_true=y_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred=y_pred,y_true=y_test):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred=y_pred,y_true=y_test):.4f}\")\n",
    "print(f\"F1 score: {f1_score(y_pred=y_pred,y_true=y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9f40b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\models\\\\duplicate_.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(rf,'..\\\\models\\\\duplicate_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9417bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate\n",
      "Prediction took 0.7340 seconds\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "rf_model = joblib.load('..\\\\models\\\\duplicate_.pkl')\n",
    "\n",
    "s1 = 'where do i learn data science'\n",
    "s2 = 'resources to get started with data science'\n",
    "\n",
    "sample1 = w2v_sentence(s1,s2)\n",
    "\n",
    "y_pred = rf_model.predict([sample1])\n",
    "print(\"Duplicate\" if y_pred==1 else 'Non Duplicate')\n",
    "print(f\"Prediction took {time()-start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d889e",
   "metadata": {},
   "source": [
    "Model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45870e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements in corpus: 131152\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique elements in corpus: {len(set(tuple(x) for x in corpus))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7724c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<UNK>':0}\n",
    "for tokenized_sentence in corpus:\n",
    "    for word in tokenized_sentence:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9755100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_to_indices(s:str):\n",
    "    arr = []\n",
    "    for word in pre_process_paragraph(s):\n",
    "        arr.append(0 if word not in vocab else vocab[word])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98329147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = [np.concatenate([para_to_indices(sen1),para_to_indices(sen2)]) for sen1,sen2 in x_train]\n",
    "x_test = [np.concatenate([para_to_indices(sen1),para_to_indices(sen2)]) for sen1,sen2 in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d870f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # self.x[index] is already a concatenated numpy array of indices\n",
    "        return torch.tensor(self.x[index], dtype=torch.long), torch.tensor(self.y[index], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58908beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train,y_train)\n",
    "test_dataset = CustomDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc403948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a5b6937a30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faa9657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_pad(batch):\n",
    "    \"\"\"\n",
    "    Collate function to pad sequences in a batch to the same length.\n",
    "    Args:\n",
    "        batch: list of (tensor, label) tuples\n",
    "    Returns:\n",
    "        padded_tensors: tensor of shape (batch_size, max_seq_len)\n",
    "        labels: tensor of shape (batch_size,)\n",
    "    \"\"\"\n",
    "    sequences, labels = zip(*batch)\n",
    "    # Pad sequences to the length of the longest sequence in the batch\n",
    "    padded_tensors = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "    return padded_tensors, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=32,collate_fn=collate_pad)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=True,collate_fn=collate_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8af0b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2b62e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=150, dropout=0.3, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            num_layers=4,\n",
    "            dropout=dropout,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear = nn.Linear(hidden_size * 2, 1)  # hidden_size * 2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.embedding(x)\n",
    "        _, (hd, _) = self.lstm(embedding)\n",
    "        # hd shape: (num_layers * num_directions, batch, hidden_size)\n",
    "        # For bidirectional, concatenate last layer's forward and backward hidden states\n",
    "        out = torch.cat((hd[-2], hd[-1]), dim=1)  # shape: (batch, hidden_size*2)\n",
    "        out = self.dropout(out)\n",
    "        return self.linear(out).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c41a38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=256, num_heads=4, num_layers=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out = self.transformer(emb)\n",
    "        out = out.mean(dim=1)  # Pooling\n",
    "        return self.linear(out).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3216a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(vocab), 100)\n",
    "encoder_layer = nn.TransformerEncoderLayer(\n",
    "    d_model=100,\n",
    "    nhead=4,\n",
    "    dropout=0.3,\n",
    "    batch_first=True\n",
    ")\n",
    "transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "linear = nn.Linear(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2947b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,     2,     3,     4,     1,     2,     3, 36321])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg = train_dataset[0][0]\n",
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "205df444",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = 0\n",
    "for ele in train_loader:\n",
    "    eg = ele[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6c5e41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 23, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = embedding(eg)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91af9be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 23, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = transformer(out)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7a54b4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = dropout(hn[-1])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99b5ea1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 23, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = linear(out1)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "df771735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ffa1835",
   "metadata": {},
   "outputs": [],
   "source": [
    "neta = 2e-4\n",
    "lambda_ = 3e-4\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b92562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and device\n",
    "model = MyNN()\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=neta,weight_decay=lambda_)\n",
    "\n",
    "# loss fn\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "75fb3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ====> Loss: 46.1961\n",
      "Epoch: 2 ====> Loss: 43.3003\n",
      "Epoch: 3 ====> Loss: 41.9129\n",
      "Epoch: 4 ====> Loss: 40.7463\n",
      "Epoch: 5 ====> Loss: 39.2650\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for train_data,train_label in train_loader:\n",
    "        # move to gpu\n",
    "        train_data,train_label = train_data.to(device),train_label.to(device)\n",
    "\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        out = model(train_data)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = loss_fn(out,train_label)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch+1} ====> Loss: {total_loss/len(train_label):.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0b151485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluating model on training data...\n",
      "🎯 Test Accuracy: 73.77%\n"
     ]
    }
   ],
   "source": [
    "# Fixed evaluation function\n",
    "def evaluate_rnn_model():\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch, test_labels in test_loader:\n",
    "            test_batch, test_labels = test_batch.to(device), test_labels.to(device)\n",
    "\n",
    "            y_pred = model(test_batch)\n",
    "            \n",
    "            # ✅ Fixed prediction calculation for sigmoid output\n",
    "            predictions = (torch.sigmoid(y_pred) > 0.5).float()\n",
    "            \n",
    "            correct += (predictions == test_labels).sum().item()\n",
    "            total += test_labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"🎯 Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Run evaluation\n",
    "print(\"📊 Evaluating model on training data...\")\n",
    "test_accuracy = evaluate_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b4462b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluating model on training data...\n",
      "🎯 Test Accuracy: 79.50%\n"
     ]
    }
   ],
   "source": [
    "# Fixed evaluation function\n",
    "def evaluate_rnn_model():\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch, test_labels in train_loader:\n",
    "            test_batch, test_labels = test_batch.to(device), test_labels.to(device)\n",
    "\n",
    "            y_pred = model(test_batch)\n",
    "            \n",
    "            # ✅ Fixed prediction calculation for sigmoid output\n",
    "            predictions = (torch.sigmoid(y_pred) > 0.5).float()\n",
    "            \n",
    "            correct += (predictions == test_labels).sum().item()\n",
    "            total += test_labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"🎯 Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Run evaluation\n",
    "print(\"📊 Evaluating model on training data...\")\n",
    "test_accuracy = evaluate_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a034cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(arr):\n",
    "    arr = np.array(arr)\n",
    "    exp_arr = np.exp(arr - np.max(arr))  # for numerical stability\n",
    "    return exp_arr * 100 / exp_arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7736a461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.06106005e-07 4.53978686e-03 9.99954600e+01]\n"
     ]
    }
   ],
   "source": [
    "values = [10,20,30]\n",
    "print(softmax(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f962d",
   "metadata": {},
   "source": [
    "Using pre-trained bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "98ba42a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91748\\OneDrive\\Desktop\\pytorch\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "be0f908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2088, 102, 2026, 2171, 2003, 102], 'token_type_ids': [0, 0, 0, 0, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = tokenizer(\n",
    "    \"hello world\",\"my name is akash\",\n",
    "    max_length=8\n",
    ")\n",
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f65aedba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd4b1162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids ======> tensor([[ 101, 2016, 2003, 1037, 9882, 2450,  102, 1045, 2572, 2032,  102],\n",
      "        [ 101, 2129, 2003, 2023, 2825,  102, 2023, 2003, 5263,  102,    0]])\n",
      "token_type_ids ======> tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]])\n",
      "attention_mask ======> tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "ip = tokenizer(\n",
    "    [\"she is a gorgeous woman\",\"how is this possible\"],[\"i am him\",\"this is impossible\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "for k,v in ip.items():\n",
    "    print(k,'======>',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d130d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids ======> tensor([ 101, 2129, 2003, 2023, 2825,  102, 2023, 2003, 5263,  102,    0])\n",
      "token_type_ids ======> tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
      "attention_mask ======> tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "item = {key: torch.tensor(val[1]) for key, val in ip.items()}\n",
    "for k,v in item.items():\n",
    "    print(k,'======>',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c51c789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Extract questions from train/test splits\n",
    "train_q1 = [pair[0] for pair in x_train]\n",
    "train_q2 = [pair[1] for pair in x_train] \n",
    "test_q1 = [pair[0] for pair in x_test]\n",
    "test_q2 = [pair[1] for pair in x_test]\n",
    "\n",
    "train_encodings = tokenizer(train_q1, train_q2, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "train_dataset = CustomDataset(train_encodings, y_train)\n",
    "\n",
    "test_encodings = tokenizer(test_q1, test_q2, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "test_dataset = CustomDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6445514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "865119f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    # For binary classification with 2 labels\n",
    "    preds = logits.argmax(-1)  # Get predicted class (0 or 1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\"accuracy\": acc, 'f1_score':f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,          # 2-4 is guud\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-5,          # Lower LR\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=200,               # More frequent evaluation\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  # Your processed train CustomDataset\n",
    "    eval_dataset=test_dataset,    # Your processed test CustomDataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa34d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('./results/checkpoint-2000')\n",
    "model = model.to(device)  # 🎯 Move model to GPU\n",
    "\n",
    "# Update trainer with device-corrected model\n",
    "trainer.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7d7a079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 4:35:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.433818</td>\n",
       "      <td>0.776250</td>\n",
       "      <td>0.750696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.398466</td>\n",
       "      <td>0.801250</td>\n",
       "      <td>0.770893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.421198</td>\n",
       "      <td>0.790250</td>\n",
       "      <td>0.771015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.363325</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.784127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.398463</td>\n",
       "      <td>0.806875</td>\n",
       "      <td>0.783522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.358857</td>\n",
       "      <td>0.840375</td>\n",
       "      <td>0.802597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.363145</td>\n",
       "      <td>0.843250</td>\n",
       "      <td>0.802706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.311100</td>\n",
       "      <td>0.359652</td>\n",
       "      <td>0.843500</td>\n",
       "      <td>0.804436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.311100</td>\n",
       "      <td>0.361876</td>\n",
       "      <td>0.840875</td>\n",
       "      <td>0.806447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.355948</td>\n",
       "      <td>0.845250</td>\n",
       "      <td>0.806017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.3660341110229492, metrics={'train_runtime': 16510.0123, 'train_samples_per_second': 3.876, 'train_steps_per_second': 0.121, 'total_flos': 4209776885760000.0, 'train_loss': 0.3660341110229492, 'epoch': 2.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdab3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint='./results/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccd25406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3559\n",
      "Test Accuracy: 84.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.35594770312309265,\n",
       " 'eval_accuracy': 0.84525,\n",
       " 'eval_f1_score': 0.8060169225947978,\n",
       " 'eval_runtime': 161.4725,\n",
       " 'eval_samples_per_second': 49.544,\n",
       " 'eval_steps_per_second': 1.548,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_bert_model(trainer):\n",
    "    results = trainer.evaluate()\n",
    "    print(f\"Test Loss: {results['eval_loss']:.4f}\")\n",
    "    print(f\"Test Accuracy: {results['eval_accuracy']*100:.2f}%\" if 'eval_accuracy' in results else \"Accuracy not computed\")\n",
    "    print(f\"F1 score: {results['eval_f1_score']*100:.2f}%\" if 'eval_f1_score' in results else \"F1 score not computed\")\n",
    "    return results\n",
    "\n",
    "# Usage:\n",
    "evaluate_bert_model(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a74dabe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_path = './results/checkpoint-2000'\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device) # type:ignore\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4624e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_duplicate(question1, question2):\n",
    "    \"\"\"\n",
    "    Predict if two questions are duplicates using the trained BERT model\n",
    "    \n",
    "    Args:\n",
    "        question1 (str): First question\n",
    "        question2 (str): Second question  \n",
    "        model_path (str): Path to saved model checkpoint\n",
    "        \n",
    "    Returns:\n",
    "        dict: Prediction results with probability and classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\n",
    "        question1, \n",
    "        question2,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get probabilities\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Probability of being duplicate (class 1)\n",
    "        duplicate_prob = probabilities[0][1].item()\n",
    "    \n",
    "    return {\n",
    "        'duplicate_probability': duplicate_prob\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59dd97ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Probability: 0.8638\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "result = predict_duplicate(\n",
    "    \"what is the process of coming late?\",\n",
    "    \"what is the process of coming on time?\"\n",
    ")\n",
    "\n",
    "print(f\"Duplicate Probability: {result['duplicate_probability']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c859bad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 DUPLICATE QUESTION DETECTION TEST SUITE\n",
      "================================================================================\n",
      "\n",
      "📋 Test 1/15: Programming - Similar Intent\n",
      "------------------------------------------------------------\n",
      "Q1: How do I learn Python programming?\n",
      "Q2: What's the best way to learn Python?\n",
      "Expected: DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.8759\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 2/15: Definition - Same Concept\n",
      "------------------------------------------------------------\n",
      "Q1: What is machine learning?\n",
      "Q2: Can you explain what machine learning is?\n",
      "Expected: DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.8121\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 3/15: Health - Same Goal\n",
      "------------------------------------------------------------\n",
      "Q1: How to lose weight fast?\n",
      "Q2: What's the quickest way to lose weight?\n",
      "Expected: DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.9128\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 4/15: Location - Synonymous\n",
      "------------------------------------------------------------\n",
      "Q1: Best restaurants in New York\n",
      "Q2: Top places to eat in NYC\n",
      "Expected: DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.5402\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 5/15: Language Learning - Paraphrase\n",
      "------------------------------------------------------------\n",
      "Q1: How can I improve my English speaking skills?\n",
      "Q2: What are ways to get better at speaking English?\n",
      "Expected: DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.8975\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 6/15: Technical - Different Wording\n",
      "------------------------------------------------------------\n",
      "Q1: Why is my computer running slow?\n",
      "Q2: What causes a computer to be sluggish?\n",
      "Expected: DUPLICATE\n",
      "Model: NOT_DUPLICATE\n",
      "Probability: 0.2991\n",
      "❌ Wrong\n",
      "\n",
      "📋 Test 7/15: Completely Different Topics\n",
      "------------------------------------------------------------\n",
      "Q1: How to cook pasta?\n",
      "Q2: What is quantum physics?\n",
      "Expected: NOT_DUPLICATE\n",
      "Model: NOT_DUPLICATE\n",
      "Probability: 0.0028\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 8/15: Unrelated Domains\n",
      "------------------------------------------------------------\n",
      "Q1: Best programming language for beginners\n",
      "Q2: How to train a dog?\n",
      "Expected: NOT_DUPLICATE\n",
      "Model: NOT_DUPLICATE\n",
      "Probability: 0.0045\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 9/15: Different Daily Activities\n",
      "------------------------------------------------------------\n",
      "Q1: What is the weather today?\n",
      "Q2: How to make coffee?\n",
      "Expected: NOT_DUPLICATE\n",
      "Model: NOT_DUPLICATE\n",
      "Probability: 0.0050\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 10/15: Opposite Intent - Key Word Difference\n",
      "------------------------------------------------------------\n",
      "Q1: How to make money online?\n",
      "Q2: How to lose money online?\n",
      "Expected: NOT_DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.8061\n",
      "❌ Wrong\n",
      "\n",
      "📋 Test 11/15: Similar Topic - Different Platform\n",
      "------------------------------------------------------------\n",
      "Q1: Best Python IDE for Mac\n",
      "Q2: Best Python IDE for Windows\n",
      "Expected: NOT_DUPLICATE\n",
      "Model: NOT_DUPLICATE\n",
      "Probability: 0.3548\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 12/15: Related but Different Actions\n",
      "------------------------------------------------------------\n",
      "Q1: How to learn data science?\n",
      "Q2: How to teach data science?\n",
      "Expected: NOT_DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.8251\n",
      "❌ Wrong\n",
      "\n",
      "📋 Test 13/15: Education - Abbreviation\n",
      "------------------------------------------------------------\n",
      "Q1: What are the fundamentals of machine learning?\n",
      "Q2: What are the basics of ML?\n",
      "Expected: DUPLICATE\n",
      "Model: NOT_DUPLICATE\n",
      "Probability: 0.0083\n",
      "❌ Wrong\n",
      "\n",
      "📋 Test 14/15: Business - Similar Concept\n",
      "------------------------------------------------------------\n",
      "Q1: How to start a business?\n",
      "Q2: Steps to launch a startup\n",
      "Expected: DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.7671\n",
      "✅ Correct\n",
      "\n",
      "📋 Test 15/15: Exact Match\n",
      "------------------------------------------------------------\n",
      "Q1: What is artificial intelligence?\n",
      "Q2: What is artificial intelligence?\n",
      "Expected: DUPLICATE\n",
      "Model: DUPLICATE\n",
      "Probability: 0.8187\n",
      "✅ Correct\n",
      "\n",
      "================================================================================\n",
      "📊 TEST SUMMARY\n",
      "================================================================================\n",
      "Total Tests: 15\n",
      "Correct: 11\n",
      "Wrong: 4\n",
      "Accuracy: 73.33%\n",
      "\n",
      "📈 CATEGORY BREAKDOWN:\n",
      "  Programming - Similar Intent: 1/1 (100.0%)\n",
      "  Definition - Same Concept: 1/1 (100.0%)\n",
      "  Health - Same Goal: 1/1 (100.0%)\n",
      "  Location - Synonymous: 1/1 (100.0%)\n",
      "  Language Learning - Paraphrase: 1/1 (100.0%)\n",
      "  Technical - Different Wording: 0/1 (0.0%)\n",
      "  Completely Different Topics: 1/1 (100.0%)\n",
      "  Unrelated Domains: 1/1 (100.0%)\n",
      "  Different Daily Activities: 1/1 (100.0%)\n",
      "  Opposite Intent - Key Word Difference: 0/1 (0.0%)\n",
      "  Similar Topic - Different Platform: 1/1 (100.0%)\n",
      "  Related but Different Actions: 0/1 (0.0%)\n",
      "  Education - Abbreviation: 0/1 (0.0%)\n",
      "  Business - Similar Concept: 1/1 (100.0%)\n",
      "  Exact Match: 1/1 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "def test_duplicate_questions():\n",
    "    \"\"\"\n",
    "    Comprehensive test suite for duplicate question detection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Test cases with expected results\n",
    "    test_cases = [\n",
    "        # 🎯 OBVIOUS DUPLICATES (Should be HIGH duplicate probability)\n",
    "        {\n",
    "            \"q1\": \"How do I learn Python programming?\",\n",
    "            \"q2\": \"What's the best way to learn Python?\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Programming - Similar Intent\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"What is machine learning?\",\n",
    "            \"q2\": \"Can you explain what machine learning is?\",\n",
    "            \"expected\": \"DUPLICATE\", \n",
    "            \"category\": \"Definition - Same Concept\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"How to lose weight fast?\",\n",
    "            \"q2\": \"What's the quickest way to lose weight?\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Health - Same Goal\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"Best restaurants in New York\",\n",
    "            \"q2\": \"Top places to eat in NYC\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Location - Synonymous\"\n",
    "        },\n",
    "        \n",
    "        # 🔄 PARAPHRASES (Should be MODERATE-HIGH duplicate probability)\n",
    "        {\n",
    "            \"q1\": \"How can I improve my English speaking skills?\",\n",
    "            \"q2\": \"What are ways to get better at speaking English?\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Language Learning - Paraphrase\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"Why is my computer running slow?\",\n",
    "            \"q2\": \"What causes a computer to be sluggish?\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Technical - Different Wording\"\n",
    "        },\n",
    "        \n",
    "        # ❌ CLEAR NON-DUPLICATES (Should be LOW duplicate probability)\n",
    "        {\n",
    "            \"q1\": \"How to cook pasta?\",\n",
    "            \"q2\": \"What is quantum physics?\",\n",
    "            \"expected\": \"NOT_DUPLICATE\",\n",
    "            \"category\": \"Completely Different Topics\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"Best programming language for beginners\",\n",
    "            \"q2\": \"How to train a dog?\",\n",
    "            \"expected\": \"NOT_DUPLICATE\",\n",
    "            \"category\": \"Unrelated Domains\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"What is the weather today?\",\n",
    "            \"q2\": \"How to make coffee?\",\n",
    "            \"expected\": \"NOT_DUPLICATE\",\n",
    "            \"category\": \"Different Daily Activities\"\n",
    "        },\n",
    "        \n",
    "        # 🤔 TRICKY CASES (Edge cases that might confuse the model)\n",
    "        {\n",
    "            \"q1\": \"How to make money online?\",\n",
    "            \"q2\": \"How to lose money online?\",\n",
    "            \"expected\": \"NOT_DUPLICATE\",\n",
    "            \"category\": \"Opposite Intent - Key Word Difference\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"Best Python IDE for Mac\",\n",
    "            \"q2\": \"Best Python IDE for Windows\", \n",
    "            \"expected\": \"NOT_DUPLICATE\",\n",
    "            \"category\": \"Similar Topic - Different Platform\"\n",
    "        },\n",
    "        {\n",
    "            \"q1\": \"How to learn data science?\",\n",
    "            \"q2\": \"How to teach data science?\",\n",
    "            \"expected\": \"NOT_DUPLICATE\",\n",
    "            \"category\": \"Related but Different Actions\"\n",
    "        },\n",
    "        \n",
    "        # 📚 EDUCATIONAL CONTEXT\n",
    "        {\n",
    "            \"q1\": \"What are the fundamentals of machine learning?\",\n",
    "            \"q2\": \"What are the basics of ML?\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Education - Abbreviation\"\n",
    "        },\n",
    "        \n",
    "        # 💼 BUSINESS/CAREER\n",
    "        {\n",
    "            \"q1\": \"How to start a business?\",\n",
    "            \"q2\": \"Steps to launch a startup\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Business - Similar Concept\"\n",
    "        },\n",
    "        \n",
    "        # 🔬 IDENTICAL QUESTIONS\n",
    "        {\n",
    "            \"q1\": \"What is artificial intelligence?\",\n",
    "            \"q2\": \"What is artificial intelligence?\",\n",
    "            \"expected\": \"DUPLICATE\",\n",
    "            \"category\": \"Exact Match\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"🧪 DUPLICATE QUESTION DETECTION TEST SUITE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_tests = len(test_cases)\n",
    "    results = []\n",
    "    \n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        print(f\"\\n📋 Test {i}/{total_tests}: {test['category']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Get prediction\n",
    "        result = predict_duplicate(test[\"q1\"], test[\"q2\"])\n",
    "        \n",
    "        # Determine model prediction\n",
    "        model_prediction = \"DUPLICATE\" if result['duplicate_probability'] > 0.5 else \"NOT_DUPLICATE\"\n",
    "        \n",
    "        # Check if correct\n",
    "        is_correct = model_prediction == test[\"expected\"]\n",
    "        correct_predictions += is_correct\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            **test,\n",
    "            **result,\n",
    "            'model_prediction': model_prediction,\n",
    "            'is_correct': is_correct\n",
    "        })\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"Q1: {test['q1']}\")\n",
    "        print(f\"Q2: {test['q2']}\")\n",
    "        print(f\"Expected: {test['expected']}\")\n",
    "        print(f\"Model: {model_prediction}\")\n",
    "        print(f\"Probability: {result['duplicate_probability']:.4f}\")\n",
    "        print(f\"✅ Correct\" if is_correct else \"❌ Wrong\")\n",
    "    \n",
    "    # Summary\n",
    "    accuracy = correct_predictions / total_tests\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📊 TEST SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total Tests: {total_tests}\")\n",
    "    print(f\"Correct: {correct_predictions}\")\n",
    "    print(f\"Wrong: {total_tests - correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    # Category-wise analysis\n",
    "    print(\"\\n📈 CATEGORY BREAKDOWN:\")\n",
    "    categories = {}\n",
    "    for result in results:\n",
    "        cat = result['category']\n",
    "        if cat not in categories:\n",
    "            categories[cat] = {'correct': 0, 'total': 0}\n",
    "        categories[cat]['total'] += 1\n",
    "        if result['is_correct']:\n",
    "            categories[cat]['correct'] += 1\n",
    "    \n",
    "    for cat, stats in categories.items():\n",
    "        acc = stats['correct'] / stats['total']\n",
    "        print(f\"  {cat}: {stats['correct']}/{stats['total']} ({acc:.1%})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the tests\n",
    "test_results = test_duplicate_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576c5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
